# Projeto de Pipeline de Dados com Databricks e AWS

**Status:** üöÄ Projeto Conclu√≠do!

## 1. Objetivo do Projeto

Este projeto demonstra a constru√ß√£o de um pipeline de dados de ponta a ponta, utilizando tecnologias de nuvem e ferramentas padr√£o de mercado. O objetivo foi simular um ambiente real de engenharia de dados, processando o dataset p√∫blico de e-commerce da Olist (dispon√≠vel no Kaggle) para extrair insights de neg√≥cio. O pipeline abrange desde a ingest√£o de dados brutos at√© a cria√ß√£o de um dashboard anal√≠tico.

## 2. Arquitetura do Pipeline

A arquitetura utilizada segue o padr√£o Medallion, com as camadas Bronze, Silver e Gold, garantindo governan√ßa, qualidade e performance.

### Arquitetura do Pipeline

![Diagrama de Arquitetura](img/diagrama01.png)

![Diagrama de Arquitetura Detalhado](img/diagrama02.png)

```
[Dados Brutos em S3] --> [Databricks (Notebook 01)] --> [Camada Bronze] --> [Databricks (Notebook 02)] --> [Camada Silver] --> [Databricks (Notebook 03)] --> [Camada Gold] --> [Databricks SQL Dashboard]
```

## 3. Tecnologias Utilizadas

* **Nuvem:** AWS (S3 para o Data Lake, IAM para permiss√µes, CloudFormation para provisionamento da infraestrutura)
* **Plataforma de Dados:** Databricks
* **Motor de Processamento:** Apache Spark
* **Formato das Tabelas:** Delta Lake
* **Linguagens:** Python (PySpark) e SQL
* **Orquestra√ß√£o:** Databricks Jobs (simulado pela execu√ß√£o manual dos notebooks em sequ√™ncia)
* **Visualiza√ß√£o de Dados:** Databricks SQL Dashboards
* **Controle de Vers√£o:** Git & GitHub

## 4. Etapas do Pipeline

###  ü•â Camada Bronze (Dados Brutos)
- Os dados brutos (arquivos `.csv`) foram ingeridos do S3.
- Foram salvos como tabelas Delta na camada Bronze, mantendo seu estado original, servindo como uma fonte de verdade hist√≥rica e ponto de partida para o pipeline.

### ü•à Camada Silver (Dados Limpos e Enriquecidos)
- Leitura dos dados da camada Bronze.
- **Limpeza e Padroniza√ß√£o:** Convers√£o de tipos de dados (ex: strings para timestamp, strings para n√∫meros decimais), tratamento de valores nulos e padroniza√ß√£o de nomes de colunas.
- **Enriquecimento:** Realiza√ß√£o de um `join` entre a tabela de produtos e a de tradu√ß√£o para incluir os nomes das categorias em ingl√™s.

### ü•á Camada Gold (Dados Agregados para Neg√≥cio)
- Leitura das tabelas limpas da camada Silver.
- **Modelagem de Neg√≥cio:** Cria√ß√£o de uma tabela de fatos (`gold_analytics_orders`) atrav√©s de `joins` entre as tabelas `orders`, `order_items`, `products` e `customers`.
- **Cria√ß√£o de M√©tricas:** Adi√ß√£o de colunas calculadas, como `total_value` (pre√ßo + frete).
- O resultado √© uma tabela denormalizada e otimizada, pronta para ser consumida por ferramentas de BI.

## 5. Resultado Final: Dashboard Anal√≠tico

A tabela Gold foi utilizada no Databricks SQL para criar um dashboard interativo respondendo √† pergunta de neg√≥cio: "Quais s√£o os 10 estados com maior volume de vendas?".

### Resultado Final: Dashboard

![Dashboard de An√°lise de Vendas](img/dashboard.png)

## 6. Como Executar

1.  Configurar as permiss√µes no AWS IAM e o acesso do Databricks ao S3.
2.  Executar o notebook `01_ingestao_bronze.py` para criar a camada Bronze.
3.  Executar o notebook `02_silver_transformations.py` para criar a camada Silver.
4.  Executar o notebook `03_gold_analytics.py` para criar a camada Gold.
5.  Criar a consulta e o dashboard no ambiente Databricks SQL.

## 7. Autor

**Matheus G Monteiro**
* [LinkedIn](https://www.linkedin.com/in/gmonteiromatheus)
* [GitHub](https://github.com/monteurmatt)
